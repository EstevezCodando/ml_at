{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728fc6ba",
   "metadata": {},
   "source": [
    "# Questão 2 \n",
    "## Implementação do modelo com K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_binary\n",
      "0    218334\n",
      "1     35346\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "# Questão 2 A\n",
    "\n",
    "# 1) Carregar a base de dados\n",
    "cdc = fetch_ucirepo(id=891)\n",
    "X_all = cdc.data.features\n",
    "y = cdc.data.targets.squeeze().rename('Diabetes_binary')\n",
    "\n",
    "# 2) Combinar features e target num DataFrame\n",
    "df = pd.concat([X_all, y], axis=1)\n",
    "\n",
    "# 3) Identificar variável-alvo\n",
    "#    - “Diabetes_binary”: 0 = não diagnosticado, 1 = diagnosticado\n",
    "print(df['Diabetes_binary'].value_counts())\n",
    "\n",
    "# 4) Selecionar variáveis explicativas\n",
    "#    Conforme analise previa em Q1\n",
    "features = ['GenHlth', 'HighBP', 'HighChol', 'BMI', 'PhysActivity']\n",
    "X = df[features]\n",
    "\n",
    "# 5) Justificativa concisa\n",
    "#    - GenHlth e HighBP foram as top correlacionadas com o target (|r| ≈ 0.30 e 0.20).  \n",
    "#    - HighChol e BMI apresentam forte evidência clínica e correlação moderada.  \n",
    "#    - PhysActivity capturou padrão não-linear relevante via informação mútua.  \n",
    "#   Essas 5 variáveis formam um conjunto enxuto e informativo, otimizado para inferir risco de diabetes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4085d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição original: {0: 0.8606669820245979, 1: 0.13933301797540207}\n",
      "Distribuição treino:   {0: 0.8606659965310628, 1: 0.13933400346893723}\n",
      "Distribuição teste:    {0: 0.8606709239987386, 1: 0.13932907600126143}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Questão 2 B\n",
    "# Supondo X e y já definidos:\n",
    "# X: DataFrame com as features selecionadas\n",
    "# y: Série com a variável-alvo 'Diabetes_binary'\n",
    "\n",
    "# Realiza a separação em treino e teste de forma estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,                # Features\n",
    "    y,                # Target\n",
    "    test_size=0.2,    # 20% dos dados para teste\n",
    "    random_state=42,  # garante reprodutibilidade\n",
    "    stratify=y        # preserva a proporção de classes em ambos conjuntos\n",
    ")\n",
    "\n",
    "# Verificação das proporções originais e pós-split\n",
    "print(\"Distribuição original:\", y.value_counts(normalize=True).to_dict())\n",
    "print(\"Distribuição treino:  \", y_train.value_counts(normalize=True).to_dict())\n",
    "print(\"Distribuição teste:   \", y_test.value_counts(normalize=True).to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e043d",
   "metadata": {},
   "source": [
    "## Questão 2 B:  Separação Estratificada em Treino e Teste\n",
    "\n",
    "Para garantir que o modelo seja treinado e avaliado em subconjuntos com a mesma proporção de casos de “diabetes” e “não-diabetes” do dataset original, adotamos a **estratificação** no momento do split.\n",
    "\n",
    "**Como foi feito**  \n",
    "- Reservamos 20 % dos dados para o conjunto de teste e 80 % para o treino.  \n",
    "- Aplicamos estratificação com base na variável-alvo Diabetes_binary, mantendo a fração de casos positivos (~14 %) e negativos (~86 %) em ambos os subsets.\n",
    "\n",
    "**Por que é importante**  \n",
    "1. **Avaliação Confiável**  \n",
    "   - Preserva o desequilíbrio real da população, evitando métricas enviesadas (por exemplo, um teste com poucos casos positivos poderia superestimar a acurácia).  \n",
    "2. **Treino Representativo**  \n",
    "   - Assegura que o modelo aprenda padrões de ambas as classes na mesma proporção em que ocorrem na população, melhorando a generalização.  \n",
    "3. **Comparabilidade**  \n",
    "   - Mantém consistência estatística entre treino e teste, permitindo comparações justas entre diferentes modelos e configurações.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ad5b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  std\n",
       "GenHlth        0.0  1.0\n",
       "HighBP        -0.0  1.0\n",
       "HighChol      -0.0  1.0\n",
       "BMI            0.0  1.0\n",
       "PhysActivity   0.0  1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questão 2 C – Normalização das Variáveis Numéricas\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Instanciar o scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 1) Ajustar e transformar X_train\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# 2) Transformar X_test com os parâmetros calculados no treino\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# 3) Verificação das estatísticas após normalização\n",
    "stats = pd.concat([\n",
    "    X_train_scaled.mean().rename('mean'),\n",
    "    X_train_scaled.std().rename('std')\n",
    "], axis=1).round(3)\n",
    "\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e5ade",
   "metadata": {},
   "source": [
    "## Questão 2 C: Normalização das Variáveis Numéricas\n",
    "\n",
    "Antes de treinar o K-Nearest Neighbors, todas as features numéricas foram **normalizadas** para garantir que cada dimensão contribua de forma equilibrada na medida de similaridade entre observações.\n",
    "\n",
    "**Como fizemos**  \n",
    "- Calculamos média e desvio-padrão em cada coluna usando somente o conjunto de treino.  \n",
    "- Subtraímos a média e dividimos pelo desvio-padrão (Standard Scaling), de modo que cada feature tenha média ≈ 0 e desvio ≈ 1.  \n",
    "- Aplicamos essas mesmas estatísticas ao conjunto de teste (sem recalcular), evitando vazamento de informação.\n",
    "\n",
    "**Por que é necessário para o KNN**  \n",
    "1. **Igualar Amplitudes**  \n",
    "   - O KNN usa, por padrão, distância Euclidiana. Sem normalização, variáveis com maior escala (por exemplo, IMC variando de 15 a 50) dominariam totalmente o cálculo, enquanto variáveis binárias ou de menor amplitude seriam irrelevantes.  \n",
    "2. **Equilíbrio de Importância**  \n",
    "   - Após a padronização, cada feature contribui proporcionalmente, permitindo que fatores clínicos, comportamentais e de autoavaliação de saúde (todas na mesma escala) influenciem corretamente a definição de “vizinhança”.  \n",
    "3. **Melhor Convergência e Robustez**  \n",
    "   - Modelos baseados em distância tendem a apresentar desempenho mais estável e interpretável quando as features estão centralizadas e escalonadas, reduzindo vieses e melhorando a sensibilidade da triagem.\n",
    "\n",
    "> **Resumo:** a normalização padroniza a escala de todas as variáveis, assegurando que o KNN trate cada dimensão de forma justa e extraia o máximo de informação de cada indicador clínico e comportamental.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d5979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Melhores parâmetros: {'knn__metric': 'minkowski', 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "Melhor F1 CV (classe1): 0.2733\n",
      "\n",
      "Relatório de Classificação (Conjunto de Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8843    0.8929    0.8886     43667\n",
      "           1     0.2962    0.2785    0.2871      7069\n",
      "\n",
      "    accuracy                         0.8073     50736\n",
      "   macro avg     0.5903    0.5857    0.5878     50736\n",
      "weighted avg     0.8024    0.8073    0.8048     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Questão 2D Otimização do KNN\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 2) Pipeline de pré-processamento + KNN\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# 3) Grade de hiperparâmetros incluindo weighting\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(1, 31, 2)),   # valores ímpares de 1 a 29\n",
    "    'knn__weights': ['uniform', 'distance'],     # uniform vs distance weighted\n",
    "    'knn__metric': ['minkowski', 'euclidean']    # distância padrão\n",
    "}\n",
    "\n",
    "# 4) GridSearchCV estratificado, otimizando F1 da classe positiva\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# 5) Ajuste no conjunto de treino\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 6) Melhor combinação\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "print(f\"Melhores parâmetros: {best_params}\")\n",
    "print(f\"Melhor F1 CV (classe1): {best_score:.4f}\\n\")\n",
    "\n",
    "# 7) Avaliação final no teste\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"Relatório de Classificação (Conjunto de Teste):\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580aa0b",
   "metadata": {},
   "source": [
    "# Comentários e Análise dos Resultados (Questão 2D)\n",
    "\n",
    "## 1. Otimização via GridSearchCV  \n",
    "- **Melhores hiperparâmetros** encontrados:  \n",
    "  - `metric='minkowski'` (distância Euclidiana)  \n",
    "  - `n_neighbors=1`  \n",
    "  - `weights='uniform'`  \n",
    "- **Critério de otimização:** F1‐score da classe positiva (diabetes) em 5‐fold CV, resultando em F1 médio ≈ 0.2733.\n",
    "\n",
    "## 2. Desempenho no Conjunto de Teste\n",
    "\n",
    "| Classe | Precision | Recall  | F1-score | Support |\n",
    "|:------:|:---------:|:-------:|:--------:|:-------:|\n",
    "| 0      | 0.8843    | 0.8929  | 0.8886   | 43 667  |\n",
    "| 1      | 0.2962    | 0.2785  | 0.2871   | 7 069   |\n",
    "| **Overall** |          |         |          |         |\n",
    "| Accuracy | **0.8073** |         |          | 50 736  |\n",
    "| Macro avg | 0.5903    | 0.5857  | 0.5878   |         |\n",
    "| Weighted avg | 0.8024 | 0.8073  | 0.8048   |         |\n",
    "\n",
    "### Interpretação das Métricas\n",
    "\n",
    "1. **Classe 0 (Não-diabetes)**  \n",
    "   - Precision e recall elevados (> 0.88) — o modelo acerta a grande maioria dos não-diabéticos e faz poucos falsos positivos para essa classe.  \n",
    "   - F1 ≈ 0.89 reflete alta confiabilidade na predição “não-diabetes”.\n",
    "\n",
    "2. **Classe 1 (Diabetes)**  \n",
    "   - **Recall ≈ 0.28**: identifica apenas ~28 % dos verdadeiros portadores de diabetes → **alto risco de falsos negativos**.  \n",
    "   - **Precision ≈ 0.30**: das previsões “diabetes”, apenas ~30 % estão corretas → **muitos falsos positivos**, gerando sobrecarga de triagem.  \n",
    "   - F1 ≈ 0.29 sinaliza desempenho limitado na detecção de casos críticos.\n",
    "\n",
    "## 3. Por que K = 1?\n",
    "\n",
    "- **Maximiza o F1 médio em CV**, capturando padrões locais da classe minoritária.  \n",
    "- **Contras de K = 1**:  \n",
    "  - Tende a **overfitting**, sensível a ruídos e outliers — explicando recall e precision instáveis mesmo em CV.  \n",
    "  - Alta variância entre folds (conforme boxplots anteriores), refletindo pouca robustez.\n",
    "\n",
    "## 4. Consequências e Próximos Passos\n",
    "\n",
    "1. **Trade-off Sensibilidade vs. Robustez**  \n",
    "   - Embora K = 1 alcance o maior F1 em CV, seu baixo recall/teste e alta variância tornam-no pouco confiável em produção.  \n",
    "2. **Experimentar `weights='distance'`**  \n",
    "   - Atribuir peso maior a vizinhos mais próximos pode atualizar K = 1 para um comportamento mais suave, reduzindo falsos positivos sem sacrificar recall.  \n",
    "3. **Avaliar Ks Médios (3–7)**  \n",
    "   - Esses valores costumam manter F1 próximo ao máximo, com menor variabilidade e menos overfitting.  \n",
    "4. **Ajustar Limiar de Decisão**  \n",
    "   - Em vez de usar o limiar padrão de 0.5, alterar o threshold de probabilidade pode melhorar recall (captura mais positivos).  \n",
    "5. **Comparar com Outros Modelos**  \n",
    "   - Testar Regressão Logística, Random Forest e ensembles, avaliando AUC-ROC, curva PR e matriz de confusão, para determinar se outros algoritmos superam o KNN.  \n",
    "\n",
    "> **Resumo:**  \n",
    "> O KNN otimizado com K = 1 e `uniform` weights fornece um baseline sensível à classe minoritária, mas seu **desempenho modesto** em recall e F1 na validação final sugere a necessidade de ajustes de weighting, limiares ou a adoção de modelos mais robustos para uma triagem de diabetes eficaz.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste e tentativas adicionais para otimização dos modelos\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# 1) Configuração comum\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# 2) Pipelines com pré-processamento + modelo\n",
    "pipelines = {\n",
    "    'KNN': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'Logistic': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 3) Grades de hiperparâmetros\n",
    "param_grids = {\n",
    "    'KNN': {\n",
    "        'clf__n_neighbors': list(range(1, 16, 2)),\n",
    "        'clf__weights': ['uniform','distance'],\n",
    "        'clf__metric': ['minkowski','manhattan']\n",
    "    },\n",
    "    'Logistic': {\n",
    "        'clf__C': [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__max_depth': [None, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4) GridSearchCV para cada modelo\n",
    "best_results = {}\n",
    "for name in pipelines:\n",
    "    grid = GridSearchCV(\n",
    "        pipelines[name],\n",
    "        param_grids[name],\n",
    "        scoring=scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_results[name] = {\n",
    "        'estimator': grid.best_estimator_,\n",
    "        'cv_f1': grid.best_score_,\n",
    "        'params': grid.best_params_\n",
    "    }\n",
    "\n",
    "# 5) Avaliação final no teste\n",
    "summary = []\n",
    "for name, info in best_results.items():\n",
    "    model = info['estimator']\n",
    "    y_pred = model.predict(X_test)\n",
    "    rpt = classification_report(y_test, y_pred, output_dict=True)\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'CV F1': info['cv_f1'],\n",
    "        'Test Precision (1)': rpt['1']['precision'],\n",
    "        'Test Recall (1)': rpt['1']['recall'],\n",
    "        'Test F1 (1)': rpt['1']['f1-score']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(summary).set_index('Model')\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_libs_infnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
