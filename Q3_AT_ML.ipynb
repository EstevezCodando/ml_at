{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3c5e29",
   "metadata": {},
   "source": [
    "## Questão 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports essenciais\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5759ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_binary\n",
      "0    218334\n",
      "1     35346\n",
      "Name: count, dtype: int64\n",
      "Distribuição original: {0: 0.8606669820245979, 1: 0.13933301797540207}\n",
      "Distribuição treino:   {0: 0.8606659965310628, 1: 0.13933400346893723}\n",
      "Distribuição teste:    {0: 0.8606709239987386, 1: 0.13932907600126143}\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Melhores parâmetros: {'knn__metric': 'minkowski', 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "Melhor F1 CV (classe1): 0.2733\n",
      "\n",
      "Relatório de Classificação (Conjunto de Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8843    0.8929    0.8886     43667\n",
      "           1     0.2962    0.2785    0.2871      7069\n",
      "\n",
      "    accuracy                         0.8073     50736\n",
      "   macro avg     0.5903    0.5857    0.5878     50736\n",
      "weighted avg     0.8024    0.8073    0.8048     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Carregar a base de dados\n",
    "cdc = fetch_ucirepo(id=891)\n",
    "X_all = cdc.data.features\n",
    "y = cdc.data.targets.squeeze().rename('Diabetes_binary')\n",
    "\n",
    "# 2) Combinar features e target num DataFrame\n",
    "df = pd.concat([X_all, y], axis=1)\n",
    "\n",
    "# 3) Identificar variável-alvo\n",
    "#    - “Diabetes_binary”: 0 = não diagnosticado, 1 = diagnosticado\n",
    "print(df['Diabetes_binary'].value_counts())\n",
    "\n",
    "# 4) Selecionar variáveis explicativas\n",
    "#    Conforme analise previa em Q1\n",
    "features = ['GenHlth', 'HighBP', 'HighChol', 'BMI', 'PhysActivity']\n",
    "X = df[features]\n",
    "\n",
    "# 5) Justificativa concisa\n",
    "#    - GenHlth e HighBP foram as top correlacionadas com o target (|r| ≈ 0.30 e 0.20).  \n",
    "#    - HighChol e BMI apresentam forte evidência clínica e correlação moderada.  \n",
    "#    - PhysActivity capturou padrão não-linear relevante via informação mútua.  \n",
    "#   Essas 5 variáveis formam um conjunto enxuto e informativo, otimizado para inferir risco de diabetes.\n",
    "\n",
    "# Questão 2 B\n",
    "# Supondo X e y já definidos:\n",
    "# X: DataFrame com as features selecionadas\n",
    "# y: Série com a variável-alvo 'Diabetes_binary'\n",
    "\n",
    "# Realiza a separação em treino e teste de forma estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,                # Features\n",
    "    y,                # Target\n",
    "    test_size=0.2,    # 20% dos dados para teste\n",
    "    random_state=42,  # garante reprodutibilidade\n",
    "    stratify=y        # preserva a proporção de classes em ambos conjuntos\n",
    ")\n",
    "\n",
    "# Verificação das proporções originais e pós-split\n",
    "print(\"Distribuição original:\", y.value_counts(normalize=True).to_dict())\n",
    "print(\"Distribuição treino:  \", y_train.value_counts(normalize=True).to_dict())\n",
    "print(\"Distribuição teste:   \", y_test.value_counts(normalize=True).to_dict())\n",
    "\n",
    "\n",
    "#Questão 2D Otimização do KNN\n",
    "\n",
    "# 2) Pipeline de pré-processamento + KNN\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# 3) Grade de hiperparâmetros incluindo weighting\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(1, 31, 2)),   # valores ímpares de 1 a 29\n",
    "    'knn__weights': ['uniform', 'distance'],     # uniform vs distance weighted\n",
    "    'knn__metric': ['minkowski', 'euclidean']    # distância padrão\n",
    "}\n",
    "\n",
    "# 4) GridSearchCV estratificado, otimizando F1 da classe positiva\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# 5) Ajuste no conjunto de treino\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 6) Melhor combinação\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "print(f\"Melhores parâmetros: {best_params}\")\n",
    "print(f\"Melhor F1 CV (classe1): {best_score:.4f}\\n\")\n",
    "\n",
    "# 7) Avaliação final no teste\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"Relatório de Classificação (Conjunto de Teste):\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a829c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score por fold: [0.2696 0.2656 0.2741 0.2875 0.2696]\n",
      "Média F1 (CV):       0.2733\n",
      "Desvio Padrão (CV):  0.0076\n"
     ]
    }
   ],
   "source": [
    "# Questão 3 A) Validação Cruzada Estratificada do KNN\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Pipeline que aplica StandardScaler e o KNN com os hiperparâmetros ótimos\n",
    "pipeline_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=1,         # melhor K encontrado\n",
    "        weights='uniform',     # melhor policy de weighting\n",
    "        metric='minkowski'     # melhor métrica de distância\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Estratégia de validação cruzada estratificada (5 folds)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Executa cross-validation no conjunto de treino original\n",
    "f1_scores = cross_val_score(\n",
    "    pipeline_knn,\n",
    "    X_train,         # features de treino não escalonadas\n",
    "    y_train,         # target de treino\n",
    "    cv=cv,\n",
    "    scoring='f1',    # otimiza F1-score da classe positiva\n",
    "    n_jobs=-1        # paraleliza em todos os núcleos disponíveis\n",
    ")\n",
    "\n",
    "# Exibe resultados\n",
    "print(\"F1-score por fold:\", np.round(f1_scores, 4))\n",
    "print(\"Média F1 (CV):      \", np.round(f1_scores.mean(), 4))\n",
    "print(\"Desvio Padrão (CV): \", np.round(f1_scores.std(), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71898c3",
   "metadata": {},
   "source": [
    "## Como a Validação Cruzada Estima o Desempenho Real do Modelo\n",
    "\n",
    "1. **Uso Eficiente de Dados**  \n",
    "   - Em vez de depender de uma única divisão treino/teste, a validação cruzada (CV) utiliza todo o conjunto de treinamento em múltiplos cenários: cada porção dos dados é, em algum momento, reservada para validação.  \n",
    "   - Isso maximiza o aproveitamento do dataset, especialmente importante em problemas desbalanceados ou com poucos exemplos da classe minoritária.\n",
    "\n",
    "2. **Redução de Variância na Estimativa**  \n",
    "   - Ao calcular o F1-score em **5 folds**, obtemos cinco estimativas independentes de desempenho.  \n",
    "   - A **média** dos F1-scores representa uma projeção mais estável do que um único teste, enquanto o **desvio padrão** quantifica a consistência do modelo ao longo de diferentes subconjuntos.\n",
    "\n",
    "3. **Detecção de Overfitting**  \n",
    "   - Se o modelo estiver muito ajustado aos dados de treino, ele terá desempenho significativamente pior em algumas folds, elevando o desvio padrão.  \n",
    "   - Um baixo desvio padrão (≈ 0.0076 aqui) indica que o modelo generaliza de forma similar em diferentes amostras, sugerindo menor risco de overfitting.\n",
    "\n",
    "4. **Avaliação Realista**  \n",
    "   - A CV reflete variações naturais da população amostrada: capturar essa heterogeneidade é crucial para prever como o modelo se comportará em novos dados não vistos.  \n",
    "   - Especialmente em triagem de saúde, onde cada falso negativo pode ter alto custo, a CV fornece uma visão mais confiável da sensibilidade (recall) e do equilíbrio entre precision e recall (F1).\n",
    "\n",
    "5. **Base para Comparação**  \n",
    "   - Quando compararmos algoritmos ou ajustes de hiperparâmetros, o F1 médio em CV serve como critério **robusto e isento de viés** para escolher a melhor configuração, antes de validá‐la no conjunto de teste final.\n",
    "\n",
    "> **Resumo:**  \n",
    "> A validação cruzada transforma múltiplas divisões de treino/teste em um “termômetro” mais preciso da performance real, garantindo que o modelo KNN escolhido (K = 1, F1 médio ≈ 0.2733) seja avaliado de forma estável, representativa e confiável para a triagem de diabetes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c173919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regressão Logística (CV Estratificado) ===\n",
      "F1-score por fold: [0.4225 0.4255 0.4286 0.427  0.4252]\n",
      "Média F1 (CV):       0.4258\n",
      "Desvio Padrão (CV):  0.002\n"
     ]
    }
   ],
   "source": [
    "#Questao 3 B \n",
    "\n",
    "#Validação Cruzada Estratificada com Regressão Logística\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1) Construir pipeline com normalização e Regressão Logística\n",
    "pipeline_logistic = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('logreg', LogisticRegression(\n",
    "        class_weight='balanced',  # corrige desequilíbrio de classes\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2) Configurar validação cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3) Executar cross-validation para F1-score da classe positiva\n",
    "f1_scores_logreg = cross_val_score(\n",
    "    pipeline_logistic,\n",
    "    X_train,    # features de treino originais (não escalonadas)\n",
    "    y_train,    # target de treino\n",
    "    cv=cv,\n",
    "    scoring='f1',  # F1 da classe 1\n",
    "    n_jobs=-1      # paraleliza em todos os núcleos disponíveis\n",
    ")\n",
    "\n",
    "# 4) Exibir resultados\n",
    "print(\"=== Regressão Logística (CV Estratificado) ===\")\n",
    "print(\"F1-score por fold:\", np.round(f1_scores_logreg, 4))\n",
    "print(\"Média F1 (CV):      \", np.round(f1_scores_logreg.mean(), 4))\n",
    "print(\"Desvio Padrão (CV): \", np.round(f1_scores_logreg.std(), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2193a159",
   "metadata": {},
   "source": [
    "## Avaliação da Regressão Logística em CV Estratificado\n",
    "\n",
    "- **F1‐scores por fold:** [0.4225, 0.4255, 0.4286, 0.4270, 0.4252]  \n",
    "- **Média F1 (CV):** 0.4258  \n",
    "- **Desvio Padrão (CV):** 0.0020  \n",
    "\n",
    "### Principais Observações\n",
    "\n",
    "1. **Performance Superior ao KNN**  \n",
    "   - A Regressão Logística alcançou F1 médio ≈ 0.426, bem acima dos ≈ 0.273 do KNN otimizado.  \n",
    "   - Isso indica que um modelo linear penalizado (com `class_weight='balanced'`) consegue capturar melhor os padrões de diabetes nas 5 features selecionadas.\n",
    "\n",
    "2. **Alta Consistência (Baixo Desvio Padrão)**  \n",
    "   - O desvio de ≈ 0.002 reflete **muito pouca variabilidade** entre as folds, mostrando que o modelo generaliza de forma estável em diferentes subconjuntos estratificados.\n",
    "\n",
    "3. **Impacto do `class_weight='balanced'`**  \n",
    "   - Ajustar os pesos na regressão compensou o desbalanceamento (~86/14), aumentando recall da classe positiva sem sacrificar excessivamente a precision, resultando em um F1 robusto.\n",
    "\n",
    "4. **Trade-off Viés-Variância**  \n",
    "   - A Regressão Logística, sendo menos flexível que o KNN com K=1, evita overfitting e entrega desempenho mais confiável e interpretável.\n",
    "\n",
    "---\n",
    "\n",
    "> **Conclusão Parcial:**  \n",
    "> A Regressão Logística serve como um modelo de **baseline forte**, combinando simplicidade, estabilidade e boa capacidade de detecção de casos de diabetes (F1 ≈ 0.426). Em comparação, o KNN mostrou-se menos eficaz e mais variável, justificando a adoção da Regressão Logística como ponto de partida antes de testar modelos mais complexos ou técnicas de ensemble.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbf03c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Árvore de Decisão (CV Estratificado) ===\n",
      "F1-score por fold: [0.4151 0.4197 0.4227 0.4231 0.4213]\n",
      "Média F1 (CV):       0.4204\n",
      "Desvio Padrão (CV):  0.0029\n"
     ]
    }
   ],
   "source": [
    "# Questão 3B) Validação Cruzada Estratificada com Árvore de Decisão \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# 1) Pipeline com Árvore de Decisão e balanceamento de classes\n",
    "pipeline_tree = Pipeline([\n",
    "    ('clf', DecisionTreeClassifier(\n",
    "        class_weight='balanced', \n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2) Estratégia de validação cruzada estratificada (5 folds)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3) Executar cross-validation usando F1-score da classe positiva\n",
    "f1_scores_tree = cross_val_score(\n",
    "    pipeline_tree,\n",
    "    X_train,    # features de treino originais\n",
    "    y_train,    # target de treino\n",
    "    cv=cv,\n",
    "    scoring='f1',  \n",
    "    n_jobs=-1      \n",
    ")\n",
    "\n",
    "# 4) Exibir resultados\n",
    "print(\"=== Árvore de Decisão (CV Estratificado) ===\")\n",
    "print(\"F1-score por fold:\", np.round(f1_scores_tree, 4))\n",
    "print(\"Média F1 (CV):      \", np.round(f1_scores_tree.mean(), 4))\n",
    "print(\"Desvio Padrão (CV): \", np.round(f1_scores_tree.std(), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fec6f6",
   "metadata": {},
   "source": [
    "## Avaliação da Árvore de Decisão em CV Estratificado\n",
    "\n",
    "- **F1-scores por fold:** [0.4151, 0.4197, 0.4227, 0.4231, 0.4213]  \n",
    "- **Média F1 (CV):** 0.4204  \n",
    "- **Desvio Padrão (CV):** 0.0029  \n",
    "\n",
    "### Principais Observações\n",
    "\n",
    "1. **Desempenho Competitivo**  \n",
    "   - A Árvore de Decisão alcançou F1 médio ≈ 0.420, muito próximo ao da Regressão Logística (≈ 0.426) e bem acima do KNN (≈ 0.273).  \n",
    "   - Isso mostra que um modelo não linear simples, com `class_weight='balanced'`, captura interações importantes entre as features.\n",
    "\n",
    "2. **Variabilidade Moderada**  \n",
    "   - O desvio padrão (≈ 0.003) é um pouco maior que o da Regressão Logística (≈ 0.002), mas ainda baixo, indicando estabilidade razoável entre as folds.\n",
    "\n",
    "3. **Complexidade vs. Simplicidade**  \n",
    "   - Diferentemente da Regressão Logística, a Árvore de Decisão não exige normalização nem engenharia de features polinomiais para obter bom desempenho.  \n",
    "   - Contudo, corre o risco de overfitting se não for regularizada (poda, profundidade limitada).\n",
    "## Questao 3 C\n",
    "### Comparação Rápida\n",
    "\n",
    "\n",
    "| Modelo                | Média F1 (CV) | Desvio Padrão |\n",
    "|-----------------------|--------------:|--------------:|\n",
    "| KNN (K=1)             |        0.2733 |        0.0076 |\n",
    "| Regressão Logística   |        0.4258 |        0.0020 |\n",
    "| Árvore de Decisão     |        0.4204 |        0.0029 |\n",
    "\n",
    "- A **Regressão Logística** lidera em F1 médio e robustez, mas requer normalização.  \n",
    "- A **Árvore de Decisão** quase empata, sem precisar de pré-processamento complexo, e pode ser beneficiada por poda.  \n",
    "- O **KNN** fica atrás, evidenciando baixa capacidade de generalização para este problema.\n",
    "\n",
    "> **Próximo passo (Questão 3C):**  \n",
    "> Comparar formalmente esses modelos (Logística vs. Árvore de Decisão vs. KNN) no conjunto de teste, apresentando métricas e escolhendo o mais robusto para implantação.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a07f8a",
   "metadata": {},
   "source": [
    "## Questao 3 D\n",
    "\n",
    "## Indícios de Overfitting e Underfitting nos Modelos\n",
    "\n",
    "| Modelo                | Métrica CV (F1 médio) | Desvio Padrão | Pré‐processamento           | Complexidade            |\n",
    "|-----------------------|----------------------:|--------------:|-----------------------------|-------------------------|\n",
    "| **KNN (K=1)**         | 0.2733               | 0.0076        | Escalonamento               | Alta (K mínimo)         |\n",
    "| **Regressão Logística** | 0.4258             | 0.0020        | Escalonamento, balanceamento | Baixa (linear)          |\n",
    "| **Árvore de Decisão** | 0.4204               | 0.0029        | Balanceamento               | Moderada (sem poda)     |\n",
    "\n",
    "### KNN (K = 1)\n",
    "- **Alto viés de variância**: K muito baixo “memoriza” pontos de treino, capturando ruído (overfitting).  \n",
    "- **Sinais**: desempenho instável entre folds (desvio padrão 0.0076) e fraca generalização (CV F1 ≈ 0.27 vs. teste F1 ≈ 0.29).  \n",
    "- **Complexidade**: modelo extremamente local, alta variância, baixo viés de treinamento, mas sob alto risco de overfitting.\n",
    "\n",
    "### Regressão Logística\n",
    "- **Baixa variância, maior viés**: modelo linear impõe restrições formais (underfitting leve), mas com balanceamento de classes reduz o viés contra a minoritária.  \n",
    "- **Sinais**: CV F1 alto e extremamente consistente (desvio 0.002), indicando boa generalização e baixo overfitting.  \n",
    "- **Complexidade**: simples, controlada por `class_weight`, trade-off adequado entre viés e variância.\n",
    "\n",
    "### Árvore de Decisão\n",
    "- **Moderada variância e baixo viés**: árvores tendem a sobreajustar se não podadas (underfitting raro, mas possível).  \n",
    "- **Sinais**: CV F1 (0.4204) quase igual ao da regressão, mas desvio um pouco maior (0.0029), sugerindo leve sensibilidade às amostras de treino.  \n",
    "- **Complexidade**: flexível, pode capturar não‐linearidades; sem poda, indicada leve tendência a overfitting, mas não severa neste contexto.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusão sobre Viés–Variância\n",
    "- **Overfitting**: claro no KNN com K=1 (alta variância).  \n",
    "- **Underfitting**: não visto; mesmo o modelo linear atinge bom F1, sem indicar capacidade excessivamente limitada.  \n",
    "- **Melhor Equilíbrio**: Regressão Logística—baixa variância e viés controlado via `class_weight`, resultando em performance estável e robusta.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_libs_infnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
